{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TdBVsyer1yj4XgHaYyljp89OMQzhljrk","timestamp":1764299154889}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Importación de datos"],"metadata":{"id":"NoiTN8LIv5lX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rBFIE2pjX8Yr","executionInfo":{"status":"ok","timestamp":1764305717048,"user_tz":300,"elapsed":18363,"user":{"displayName":"SANTIAGO ORTEGA RONCANCIO","userId":"06220729215775844602"}},"outputId":"264f7219-f9f7-4d74-fcd8-aa2210d36e38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#Instalar las librerias necesarias para la ejecución\n","\n","!pip install gdown\n","\n","import gdown\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler"],"metadata":{"collapsed":true,"id":"RFDSU2CpYhCb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ID del archivo en Google Drive\n","file_id = \"1nWl7vNpI2XHd_B6cwAgIAYClQ3J9F6r1\"\n","download_url = f\"https://drive.google.com/uc?id={file_id}\"\n","\n","# Descargar el archivo CSV a local\n","output = \"archivo.csv\"\n","gdown.download(download_url, output, quiet=False)\n","\n","# Leer CSV con pandas\n","df = pd.read_csv(output)\n","\n","\n","\n","# Importacion del test\n","\n","file_id = \"1c9lxChxn6YhWD9YJCBSdxmA3Xt-fasN7\"\n","download_url = f\"https://drive.google.com/uc?id={file_id}\"\n","\n","output = \"archivo.csv\"\n","gdown.download(download_url, output, quiet=False)\n","\n","df_test=pd.read_csv(output)\n"],"metadata":{"id":"uSCYUuQRYlWE","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El dataframe lo guardamos en la variable df y el que vamos a modificar va a estar en la variable dfa"],"metadata":{"id":"C-8MTfsBZa_6"}},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"09DHcfdGcyBU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Lo primero que vamos a hacer es resolver el problema de los datos vacios"],"metadata":{"id":"uwCCG774aMjb"}},{"cell_type":"code","source":["print(\"El porcentaje de datos vacios en el df es de: \")\n","print((((df.isna().sum().sum())/(df.shape[0]*df.shape[1]))*(100)),\"%\")\n"],"metadata":{"id":"1xpyJbzrabgy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vemos que tenemos demasiados valores vacios, estos representan aproximadamente el 2% del data frame"],"metadata":{"id":"BieVWMrAbLvU"}},{"cell_type":"code","metadata":{"id":"6e1b3d4a"},"source":["import pandas as pd\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","import unicodedata\n","import pandas as pd\n","import numpy as np\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","import pandas as pd\n","import numpy as np\n","\n","import pandas as pd\n","import numpy as np\n","\n","def preprocess_dataframe(df_input):\n","    \"\"\"\n","    Preprocesa el DataFrame completamente:\n","    - Convierte TODO a numérico\n","    - Elimina columnas duplicadas\n","    - Maneja valores faltantes\n","    - Optimiza tipos de datos\n","    \"\"\"\n","    df = df_input.copy()\n","    df = df.replace(['nan', 'NaN', '', 'None', 'null'], np.nan)\n","    cols_to_drop = ['ID', 'PERIODO_ACADEMICO']\n","    existing_to_drop = [col for col in cols_to_drop if col in df.columns]\n","    if existing_to_drop:\n","        df = df.drop(columns=existing_to_drop)\n","        print(\"Eliminadas columnas: {existing_to_drop}\")\n","\n","    target_col = 'RENDIMIENTO_GLOBAL'\n","    has_target = target_col in df.columns\n","    cols_one_hot = ['E_PRGM_ACADEMICO', 'E_PRGM_DEPARTAMENTO']\n","    cols_ordinales = [\n","        'E_VALORMATRICULAUNIVERSIDAD',\n","        'E_HORASSEMANATRABAJA',\n","        'F_ESTRATOVIVIENDA',\n","        'F_EDUCACIONPADRE',\n","        'F_EDUCACIONMADRE'\n","    ]\n","\n","    # Columnas binarias\n","    cols_binarias = [\n","        'F_TIENEINTERNET',\n","        'F_TIENELAVADORA',\n","        'F_TIENEAUTOMOVIL',\n","        'E_PRIVADO_LIBERTAD',\n","        'E_PAGOMATRICULAPROPIO',\n","        'F_TIENECOMPUTADOR',\n","        'F_TIENEINTERNET_1'\n","    ]\n","\n","    # Columnas numéricas\n","    cols_numericas = ['INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4']\n","\n","    # 4. ONE-HOT ENCODING\n","    cols_to_encode = [col for col in cols_one_hot if col in df.columns]\n","\n","    if cols_to_encode:\n","        print(\"Aplicando One-Hot Encoding a: {cols_to_encode}\")\n","        for col in cols_to_encode:\n","            # Rellenar NaN con 'Desconocido'\n","            df[col] = df[col].fillna('Desconocido').astype(str)\n","\n","        # One-hot encoding\n","        df = pd.get_dummies(df, columns=cols_to_encode, prefix=cols_to_encode,\n","                           dtype='int8', drop_first=False)\n","\n","    # 5. ORDINAL ENCODING\n","\n","    # 5.1 E_VALORMATRICULAUNIVERSIDAD\n","    if 'E_VALORMATRICULAUNIVERSIDAD' in df.columns:\n","        print(\"Procesando E_VALORMATRICULAUNIVERSIDAD\")\n","        orden_matricula = {\n","            'No pagó matrícula': 0,\n","            'Menos de 500 mil': 1,\n","            'Entre 500 mil y menos de 1 millón': 2,\n","            'Entre 1 millón y menos de 2.5 millones': 3,\n","            'Entre 2.5 millones y menos de 4 millones': 4,\n","            'Entre 4 millones y menos de 5.5 millones': 5,\n","            'Entre 5.5 millones y menos de 7 millones': 6,\n","            'Más de 7 millones': 7\n","        }\n","        df['E_VALORMATRICULAUNIVERSIDAD'] = df['E_VALORMATRICULAUNIVERSIDAD'].astype(str).map(orden_matricula)\n","        df['E_VALORMATRICULAUNIVERSIDAD'] = pd.to_numeric(df['E_VALORMATRICULAUNIVERSIDAD'], errors='coerce')\n","        moda = df['E_VALORMATRICULAUNIVERSIDAD'].mode()[0] if len(df['E_VALORMATRICULAUNIVERSIDAD'].mode()) > 0 else 3\n","        df['E_VALORMATRICULAUNIVERSIDAD'] = df['E_VALORMATRICULAUNIVERSIDAD'].fillna(moda).astype('int8')\n","\n","    # 5.2 E_HORASSEMANATRABAJA\n","    if 'E_HORASSEMANATRABAJA' in df.columns:\n","        print(\"Procesando E_HORASSEMANATRABAJA\")\n","        orden_horas = {\n","            '0': 0,\n","            'Menos de 10 horas': 1,\n","            'Entre 11 y 20 horas': 2,\n","            'Entre 21 y 30 horas': 3,\n","            'Más de 30 horas': 4\n","        }\n","        df['E_HORASSEMANATRABAJA'] = df['E_HORASSEMANATRABAJA'].astype(str).map(orden_horas)\n","        df['E_HORASSEMANATRABAJA'] = pd.to_numeric(df['E_HORASSEMANATRABAJA'], errors='coerce')\n","        moda = df['E_HORASSEMANATRABAJA'].mode()[0] if len(df['E_HORASSEMANATRABAJA'].mode()) > 0 else 1\n","        df['E_HORASSEMANATRABAJA'] = df['E_HORASSEMANATRABAJA'].fillna(moda).astype('int8')\n","\n","    # 5.3 F_ESTRATOVIVIENDA\n","    if 'F_ESTRATOVIVIENDA' in df.columns:\n","        orden_estrato = {\n","            'Sin Estrato': 0,\n","            'Estrato 1': 1,\n","            'Estrato 2': 2,\n","            'Estrato 3': 3,\n","            'Estrato 4': 4,\n","            'Estrato 5': 5,\n","            'Estrato 6': 6\n","        }\n","        df['F_ESTRATOVIVIENDA'] = df['F_ESTRATOVIVIENDA'].astype(str).map(orden_estrato)\n","        df['F_ESTRATOVIVIENDA'] = pd.to_numeric(df['F_ESTRATOVIVIENDA'], errors='coerce')\n","        mediana = df['F_ESTRATOVIVIENDA'].median()\n","        df['F_ESTRATOVIVIENDA'] = df['F_ESTRATOVIVIENDA'].fillna(mediana).astype('int8')\n","\n","    # 5.4 F_EDUCACIONPADRE\n","    if 'F_EDUCACIONPADRE' in df.columns:\n","        orden_educacion = {\n","            'Ninguno': 0,\n","            'Primaria incompleta': 1,\n","            'Primaria completa': 2,\n","            'Secundaria (Bachillerato) incompleta': 3,\n","            'Secundaria (Bachillerato) completa': 4,\n","            'Técnica o tecnológica incompleta': 5,\n","            'Técnica o tecnológica completa': 6,\n","            'Educación profesional incompleta': 7,\n","            'Educación profesional completa': 8,\n","            'Postgrado': 9,\n","            'No sabe': 0,\n","            'No Aplica': 0\n","        }\n","        df['F_EDUCACIONPADRE'] = df['F_EDUCACIONPADRE'].astype(str).map(orden_educacion)\n","        df['F_EDUCACIONPADRE'] = pd.to_numeric(df['F_EDUCACIONPADRE'], errors='coerce')\n","        mediana = df['F_EDUCACIONPADRE'].median()\n","        df['F_EDUCACIONPADRE'] = df['F_EDUCACIONPADRE'].fillna(mediana).astype('int8')\n","\n","    # 5.5 F_EDUCACIONMADRE\n","    if 'F_EDUCACIONMADRE' in df.columns:\n","        orden_educacion = {\n","            'Ninguno': 0,\n","            'Primaria incompleta': 1,\n","            'Primaria completa': 2,\n","            'Secundaria (Bachillerato) incompleta': 3,\n","            'Secundaria (Bachillerato) completa': 4,\n","            'Técnica o tecnológica incompleta': 5,\n","            'Técnica o tecnológica completa': 6,\n","            'Educación profesional incompleta': 7,\n","            'Educación profesional completa': 8,\n","            'Postgrado': 9,\n","            'No Aplica': 0\n","        }\n","        df['F_EDUCACIONMADRE'] = df['F_EDUCACIONMADRE'].astype(str).map(orden_educacion)\n","        df['F_EDUCACIONMADRE'] = pd.to_numeric(df['F_EDUCACIONMADRE'], errors='coerce')\n","        mediana = df['F_EDUCACIONMADRE'].median()\n","        df['F_EDUCACIONMADRE'] = df['F_EDUCACIONMADRE'].fillna(mediana).astype('int8')\n","\n","    # 6. COLUMNAS BINARIAS (Si/No, S/N)\n","    for col in cols_binarias:\n","        if col in df.columns:\n","            # Convertir todo a string primero\n","            df[col] = df[col].astype(str).str.strip().str.lower()\n","\n","            # Mapear a 0/1\n","            mapeo = {\n","                'si': 1, 'sí': 1, 's': 1, '1': 1, '1.0': 1, 'true': 1,\n","                'no': 0, 'n': 0, '0': 0, '0.0': 0, 'false': 0,\n","                'nan': np.nan, 'none': np.nan\n","            }\n","            df[col] = df[col].map(mapeo)\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","            # Rellenar NaN con moda\n","            moda = df[col].mode()[0] if len(df[col].mode()) > 0 else 0\n","            df[col] = df[col].fillna(moda).astype('int8')\n","\n","    # 7. VARIABLE OBJETIVO (RENDIMIENTO_GLOBAL)\n","    if has_target:\n","        orden_rendimiento = {\n","            'bajo': 0,\n","            'medio-bajo': 1,\n","            'medio-alto': 2,\n","            'alto': 3\n","        }\n","        df[target_col] = df[target_col].astype(str).str.lower().str.strip().map(orden_rendimiento)\n","        df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n","        # NO rellenar NaN en el target, dejar como está\n","        df[target_col] = df[target_col].astype('int8')\n","\n","    # 8. COLUMNAS NUMÉRICAS (INDICADORES)\n","    for col in cols_numericas:\n","        if col in df.columns:\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","            mediana = df[col].median()\n","            df[col] = df[col].fillna(mediana).astype('float32')\n","\n","    # 9. PROCESAR CUALQUIER COLUMNA RESTANTE (por si acaso)\n","    for col in df.columns:\n","        if df[col].dtype == 'object':\n","            # Intentar convertir a numérico\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","            # Rellenar NaN con 0\n","            df[col] = df[col].fillna(0).astype('float32')\n","\n","    # 10. LIMPIAR NOMBRES DE COLUMNAS (quitar caracteres especiales)\n","\n","    df.columns = df.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n","    df.columns = df.columns.str.strip('_')\n","    df.columns = df.columns.str.replace('__+', '_', regex=True)  # Reemplazar múltiples _ por uno solo\n","\n","    # 11. ELIMINAR COLUMNAS DUPLICADAS\n","    duplicadas_antes = df.columns.duplicated().sum()\n","    if duplicadas_antes > 0:\n","        df = df.loc[:, ~df.columns.duplicated()]\n","\n","\n","\n","    # Verificar que todo es numérico\n","    non_numeric = df.select_dtypes(exclude=[np.number]).columns.tolist()\n","\n","    # Verificar NaN\n","    nan_counts = df.isnull().sum()\n","    if nan_counts.sum() > 0:\n","        print(f\"\\n Valores NaN encontrados en:\")\n","        print(nan_counts[nan_counts > 0])\n","    else:\n","        print(\" No hay valores NaN\")\n","\n","    print(\"=\"*60 + \"\\n\")\n","\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def alinear_columnas(X_train, X_test):\n","    \"\"\"Alinea columnas de X_test con X_train\"\"\"\n","    # Agregar columnas faltantes con 0\n","    missing_cols = set(X_train.columns) - set(X_test.columns)\n","    for col in missing_cols:\n","        X_test[col] = 0\n","\n","    # Eliminar columnas extra\n","    extra_cols = set(X_test.columns) - set(X_train.columns)\n","    X_test = X_test.drop(columns=list(extra_cols), errors='ignore')\n","\n","    # Reordenar para que coincidan\n","    X_test = X_test[X_train.columns]\n","\n","    return X_test\n"],"metadata":{"id":"WJRZHpqkSgAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes.unique()"],"metadata":{"id":"22t4CVmEDYNI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#A partir de este momento queda listo el preprocesado, entonces vamos a comenzar con el primer modelo (Random Forest)"],"metadata":{"id":"GDU5aV22qw2B"}},{"cell_type":"code","metadata":{"collapsed":true,"id":"33df62ae"},"source":["# Usar la función para preprocesar el DataFrame original\n","df = preprocess_dataframe(df)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes.unique()"],"metadata":{"id":"gi4fAp6044_K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3dd61a3f"},"source":["### Uso de la función de preprocesamiento"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import median_absolute_error, r2_score, mean_squared_error\n","from sklearn.model_selection import cross_validate, ShuffleSplit\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","!pip install lightgbm\n","import lightgbm as lgb\n"],"metadata":{"id":"rb09VpNuq9ra"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Hacemos los splits y la distribucion de los datos X y Y"],"metadata":{"id":"XPnlo3k_R49z"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","TARGET = \"RENDIMIENTO_GLOBAL\"\n","\n","y_train = df[TARGET]\n","X_train = df.drop(columns=[TARGET])\n","\n","X_test = preprocess_dataframe(df_test)\n","X_test = alinear_columnas(X_train, X_test)\n","\n","\n","\n"],"metadata":{"id":"9OZtBmWbRePT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","import pandas as pd\n","\n","# 1. ENTRENAR\n","print(\"Entrenando Random Forest...\")\n","model_rf = RandomForestClassifier(\n","    n_estimators=100,\n","    random_state=42,\n","    n_jobs=-1,\n","    verbose=1\n",")\n","\n","model_rf.fit(X_train, y_train)\n","print(\"Entrenamiento completado!\")\n","\n","# 2. PREDECIR EN TEST\n","print(\"Realizando predicciones en test...\")\n","y_test_pred = model_rf.predict(X_test)\n","\n","# 3. CREAR DATAFRAME CON RESULTADOS\n","class_mapping = {0: 'bajo', 1: 'medio-bajo', 2: 'medio-alto', 3: 'alto'}\n","\n","resultados = pd.DataFrame({\n","    'ID': range(len(X_test)),  # O usa X_test.index si tiene IDs\n","    'RENDIMIENTO_GLOBAL': [class_mapping[p] for p in y_test_pred]\n","})\n","\n","# 4. MOSTRAR Y GUARDAR\n","print(\"Distribución de predicciones:\")\n","print(resultados['RENDIMIENTO_GLOBAL'].value_counts())\n","print(\"Primeras predicciones:\")\n","print(resultados.head())\n","\n","resultados.to_csv('predicciones_random_forest.csv', index=False)\n","print(\"Predicciones guardadas!\")\n","\n","\n"],"metadata":{"id":"CfHuLxG1ROpR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PREDECIR EN TEST\n","print(\"Realizando predicciones en test...\")\n","y_test_pred = model_rf.predict(X_test)\n","\n","# Crear DataFrame con ID y predicción\n","class_mapping = {0: 'bajo', 1: 'medio-bajo', 2: 'medio-alto', 3: 'alto'}\n","\n","resultados = pd.DataFrame({\n","    'ID': df_test[\"ID\"],  # Usa el índice de X_test como ID\n","    'RENDIMIENTO_GLOBAL': [class_mapping[p] for p in y_test_pred]\n","})\n","\n","print(\"Distribución de predicciones en test:\")\n","print(resultados['RENDIMIENTO_GLOBAL'].value_counts())\n","print(\"Primeras 5 predicciones:\")\n","print(resultados.head())\n","\n","# Guardar predicciones\n","resultados.to_csv('predicciones_random_forest.csv', index=False)\n","print(\"Predicciones guardadas en 'predicciones_random_forest.csv'\")"],"metadata":{"id":"QqrVAbAmrgum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultados.head()"],"metadata":{"id":"JXz1gpLdU9jn"},"execution_count":null,"outputs":[]}]}